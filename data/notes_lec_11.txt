UNDERSTANDING PROGRAM EFFICIENCY: 2 (download slides and .py files and follow along!) 1 TODAY § Classes of complexity § Examples characteris;c of each class 2 WHY WE WANT TO UNDERSTAND EFFICIENCY OF PROGRAMS § how can we reason about an algorithm in order to predict the amount of ;me it will need to solve a problem of a par;cular size? § how can we relate choices in algorithm design to the ;me efficiency of the resul;ng algorithm?
are there fundamental limits on the amount of ;me we will need to solve a par;cular problem? 3 ORDERS OF GROWTH: RECAP Goals: § want to evaluate program’s efficiency when input is very big § want to express the growth of program’s run 5me as input size grows § want to put an upper bound on growth – as ;ght as possible § do not need to be precise: “order of” not “exact” growth § we will look at largest factors in run ;me (which sec;on of the program will take the longest to run?) § thus, generally we want 5ght upper bound on growth, as func5on of size of input, in worst case 4 COMPLEXITY CLASSES: RECAP § O(1) denotes constant running ;me § O(log n) denotes logarithmic running ;me § O(n) denotes linear running ;me § O(n log n) denotes log-linear running ;me § O(nc) denotes polynomial running ;me (c is a constant) § O(cn) denotes exponen;al running ;me (c is a constant being raised to a power based on size of input) 5 COMPLEXITY CLASSES ORDERED LOW TO HIGH O(1) : constant O(log n) : logarithmic O(n) : linear O(n log n): loglinear O(nc) : polynomial O(cn) : exponen;al 6 COMPLEXITY GROWTH CLASS n=10 = 100 = 1000 = 1000000 O(1) 1 1 1 1 O(log n) 1 2 3 6 O(n) 10 100 1000 1000000 O(n log n) 10 200 3000 6000000 O(n^2) 100 10000 1000000 1000000000000 O(2^n) 1024 12676506 1071508607186267320948425049060 Good luck!! 00228229 0018105614048117055336074437503 40149670 8837035105112493612249319837881 3205376 5695858127594672917553146825187 1452856923140435984577574698574 8039345677748242309854210746050 6237114187795418215304647498358 1941267398767559165543946077062 9145711964776865421676604298316 52624386837205668069376 7 CONSTANT COMPLEXITY § complexity independent of inputs § very few interes;ng algorithms in this class, but can oYen have pieces that fit this class § can have loops or recursive calls, but ONLY IF number of itera;ons or calls independent of size of input 8 LOGARITHMIC COMPLEXITY § complexity grows as log of size of one of its inputs § example:
bisec;on search
binary search of a list 9 BISECTION SEARCH § suppose we want to know if a par;cular element is present in a list § saw last ;me that we could just “walk down” the list, checking each element § complexity was linear in length of the list § suppose we know that the list is ordered from smallest to largest
saw that sequen;al search was s;ll linear in complexity
can we do becer? 10 BISECTION SEARCH 1. pick an index, i, that divides list in half 2. ask if L[i] == e 3. if not, ask if L[i] is larger or smaller than e 4. depending on answer, search leY or right half of L for e A new version of a divide-and-conquer algorithm § break into smaller version of problem (smaller list), plus some simple opera;ons § answer to smaller version is answer to original problem 11 BISECTION SEARCH COMPLEXITY ANALYSIS § finish looking through list when 1 = n/2i … so i = log n … § complexity of recursion is O(log n) – where n is len(L) 12 BISECTION SEARCH IMPLEMENTATION 1 def bisect_search1(L, e):! if L == []:! return False! elif len(L) == 1:! return L[0] == e! else:! half = len(L)//2! if L[half] > e:! return bisect_search1( L[:half], e)! else:! return bisect_search1( L[half:], e)! 13 COMPLEXITY OF FIRST BISECTION SEARCH METHOD § implementa5on 1 – bisect_search1
O(log n) bisec;on search calls
On each recursive call, size of range to be searched is cut in half
If original range is of size n, in worst case down to range of size 1 when n/(2^k) = 1; or when k = log n
O(n) for each bisec;on search call to copy list
This is the cost to set up each call, so do this for each level of recursion
O(log n) * O(n) à O(n log n)
if we are really careful, note that length of list to be copied is also halved on each recursive call
turns out that total cost to copy is O(n) and this dominates the log n cost due to the recursive calls 14 BISECTION SEARCH ALTERNATIVE § s;ll reduce size of problem by factor of two on each step § but just keep track of low and high por;on of list to be searched § avoid copying the list § complexity of recursion is again O(log n) – where n is len(L) 15 BISECTION SEARCH IMPLEMENTATION 2 def bisect_search2(L, e):! def bisect_search_helper(L, e, low, high):! if high == low:! return L[low] == e! mid = (low + high)//2! if L[mid] == e:! return True! elif L[mid] > e:! if low == mid: #nothing left to search! return False! else:! return bisect_search_helper(L, e, low, mid - 1)! else:! return bisect_search_helper(L, e, mid + 1, high)! if len(L) == 0:! return False! else:! return bisect_search_helper(L, e, 0, len(L) - 1)! 16 COMPLEXITY OF SECOND BISECTION SEARCH METHOD § implementa5on 2 – bisect_search2 and its helper
O(log n) bisec;on search calls
On each recursive call, size of range to be searched is cut in half
If original range is of size n, in worst case down to range of size 1 when n/(2^k) = 1; or when k = log n
pass list and indices as parameters
list never copied, just re-passed as a pointer
thus O(1) work on each recursive call
O(log n) * O(1) à O(log n) 17 LOGARITHMIC COMPLEXITY def intToStr(i):! digits = '0123456789'! if i == 0:! return '0'! result = ''! while i > 0:! result = digits[i%10] + result! i = i//10! return result! ! 18 LOGARITHMIC COMPLEXITY def intToStr(i):! only have to look at loop as digits = '0123456789'! no func;on calls if i == 0:! within while loop, constant return '0'! number of steps res = ''! while i > 0:! how many ;mes through res = digits[i%10] + res! loop? i = i//10!
how many ;mes can one return result! divide i by 10?
O(log(i)) 19 LINEAR COMPLEXITY § saw this last ;me
searching a list in sequence to see if an element is present
itera;ve loops 20 O() FOR ITERATIVE FACTORIAL § complexity can depend on number of itera;ve calls def fact_iter(n):! prod = 1! for i in range(1, n+1):! prod *= i! return prod! § overall O(n) – n ;mes round loop, constant cost each ;me 21 O() FOR RECURSIVE FACTORIAL def fact_recur(n):! """ assume n >= 0 """! if n <= 1: ! return 1! else: ! return n*fact_recur(n – 1)! § computes factorial recursively § if you ;me it, may no;ce that it runs a bit slower than itera;ve version due to func;on calls § s;ll O(n) because the number of func;on calls is linear in n, and constant effort to set up call § itera5ve and recursive factorial implementa;ons are the same order of growth 22 LOG-LINEAR COMPLEITY § many prac;cal algorithms are log-linear § very commonly used log-linear algorithm is merge sort § will return to this next lecture 23 POLYNOMIAL COMPLEXITY § most common polynomial algorithms are quadra;c, i.e., complexity grows with square of size of input § commonly occurs when we have nested loops or recursive func;on calls § saw this last ;me 24 EXPONENTIAL COMPLEXITY § recursive func;ons where more than one recursive call for each size of problem
Towers of Hanoi § many important problems are inherently exponen;al
unfortunate, as cost can be high
will lead us to consider approximate solu;ons as may provide reasonable answer more quickly 25 COMPLEXITY OF TOWERS OF HANOI § Let t denote ;me to solve tower of size n n § t = 2t + 1 n n-1 § = 2(2t + 1) + 1 n-2 § = 4t + 2 + 1 n-2 § = 4(2t + 1) + 2 + 1 Geometric growth n-3 § = 8t + 4 + 2 + 1 n-3 a = 2n-1 + … + 2 + 1 § = 2k t + 2k-1 + … + 4 + 2 + 1 2a = 2n + 2n-1 + ... + 2 n-k a = 2n - 1 § = 2n-1 + 2n-2 + ... + 4 + 2 + 1 § = 2n – 1 § so order of growth is O(2n) 26 EXPONENTIAL COMPLEXITY § given a set of integers (with no repeats), want to generate the collec;on of all possible subsets – called the power set § {1, 2, 3, 4} would generate
{}, {1}, {2}, {3}, {4}, {1, 2}, {1, 3}, {1, 4}, {2, 3}, {2, 4}, {3, 4}, {1, 2, 3}, {1, 2, 4}, {1, 3, 4}, {2, 3, 4}, {1, 2, 3, 4} § order doesn’t macer
{}, {1}, {2}, {1, 2}, {3}, {1, 3}, {2, 3}, {1, 2, 3}, {4}, {1, 4}, {2, 4}, {1, 2, 4}, {3, 4}, {1, 3, 4}, {2, 3, 4}, {1, 2, 3, 4} 27 POWER SET – CONCEPT § we want to generate the power set of integers from 1 to n § assume we can generate power set of integers from 1 to n-1 § then all of those subsets belong to bigger power set (choosing not include n); and all of those subsets with n added to each of them also belong to the bigger power set (choosing to include n) § {}, {1}, {2}, {1, 2}, {3}, {1, 3}, {2, 3}, {1, 2, 3}, {4}, {1, 4}, {2, 4}, {1, 2, 4}, {3, 4}, {1, 3, 4}, {2, 3, 4}, {1, 2, 3, 4} § nice recursive descrip;on! 28 EXPONENTIAL COMPLEXITY def genSubsets(L):! res = []! if len(L) == 0:! return [[]] #list of empty list! smaller = genSubsets(L[:-1]) # all subsets without last element! extra = L[-1:] # create a list of just last element! new = []! for small in smaller:! new.append(small+extra) # for all smaller solutions, add one with last element! return smaller+new # combine those with last element and those without! 29 EXPONENTIAL COMPLEXITY def genSubsets(L):! assuming append is constant ;me res = []! if len(L) == 0:! ;me includes ;me to solve return [[]] ! smaller problem, plus ;me smaller = genSubsets(L[:-1])! needed to make a copy of extra = L[-1:]! all elements in smaller new = []! problem for small in smaller:! new.append(small+extra)! return smaller+new! 30 EXPONENTIAL COMPLEXITY def genSubsets(L):! but important to think res = []! about size of smaller if len(L) == 0:! know that for a set of size return [[]] ! k there are 2k cases smaller = genSubsets(L[:-1])! extra = L[-1:]! how can we deduce new = []! overall complexity? for small in smaller:! new.append(small+extra)! return smaller+new! 31 EXPONENTIAL COMPLEXITY § let t denote ;me to solve problem of size n n § let s denote size of solu;on for problem of size n n § t = t + s + c (where c is some constant number of n n-1 n-1 opera;ons) § t = t + 2n-1 + c n n-1 § = t + 2n-2 + c + 2n-1 + c n-2 Thus § = t + 2n-k + … + 2n-1 + kc n-k compu;ng § = t + 20 + ... + 2n-1 + nc power set is 0 § = 1 + 2n + nc O(2n) 32 COMPLEXITY CLASSES § O(1) – code does not depend on size of problem § O(log n) – reduce problem in half each ;me through process § O(n) – simple itera;ve or recursive programs § O(n log n) – will see next ;me § O(nc) – nested loops or recursive calls § O(cn) – mul;ple recursive calls at each level 33 SOME MORE EXAMPLES OF ANALYZING COMPLEXITY 34 COMPLEXITY OF ITERATIVE FIBONACCI def fib_iter(n):! § Best case: if n == 0:! return 0! O(1) elif n == 1:! § Worst case: return 1! else:! O(1) + O(n) + O(1) è O(n) fib_i = 0! fib_ii = 1! for i in range(n-1):! tmp = fib_i! fib_i = fib_ii! fib_ii = tmp + fib_ii! return fib_ii ! 36 COMPLEXITY OF RECURSIVE FIBONACCI def fib_recur(n):! """ assumes n an int >= 0 """! if n == 0:! return 0! elif n == 1:! return 1! else:! return fib_recur(n-1) + fib_recur(n-2)! § Worst case: O(2n) 37 COMPLEXITY OF RECURSIVE FIBONACCI fib(5) fib(4) fib(3) fib(3) fib(2) fib(2) fib(1) fib(2) fib(1) § actually can do a bit becer than 2n since tree of cases thins out to right § but complexity is s;ll exponen;al 38 BIG OH SUMMARY § compare efficiency of algorithms
nota;on that describes growth
lower order of growth is becer
independent of machine or specific implementa;on § use Big Oh
describe order of growth
asympto5c nota5on
upper bound
worst case analysis 40 COMPLEXITY OF COMMON PYTHON FUNCTIONS § Lists: n is len(L) § Dic;onaries: n is len(d)
index O(1) § worst case
store O(1)
index O(n)
length O(1)
store O(n)
append O(1)
length O(n)
== O(n)
delete O(n)
remove O(n)
itera;on O(n)
copy O(n) § average case
reverse O(n)
index O(1)
itera;on O(n)
store O(1)
in list O(n)
delete O(1)
itera;on O(n) 41 MIT OpenCourseWare https://ocw.mit.edu 6.0001 Introduction to Computer Science and Programming in Python Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.