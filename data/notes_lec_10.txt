UNDERSTANDING PROGRAM EFFICIENCY: 1 (download slides and .py files and follow along!) 1 Today § Measuring orders of growth of algorithms § Big “Oh” notaAon § Complexity classes 2 WANT TO UNDERSTAND EFFICIENCY OF PROGRAMS § computers are fast and geGng faster – so maybe efficient programs don’t maLer?
but data sets can be very large (e.g., in 2014, Google served 30,000,000,000,000 pages, covering 100,000,000 GB – how long to search brute force?)
thus, simple soluAons may simply not scale with size in acceptable manner § how can we decide which opAon for program is most efficient? § separate !me and space efficiency of a program § tradeoff between them:
can someAmes pre-compute results are stored; then use “lookup” to retrieve (e.g., memoizaAon for Fibonacci)
will focus on Ame efficiency 3 WANT TO UNDERSTAND EFFICIENCY OF PROGRAMS Challenges in understanding efficiency of soluAon to a computaAonal problem: § a program can be implemented in many different ways § you can solve a problem using only a handful of different algorithms § would like to separate choices of implementaAon from choices of more abstract algorithm 4 HOW TO EVALUATE EFFICIENCY OF PROGRAMS § measure with a !mer § count the operaAons § abstract noAon of order of growth 5 TIMING A PROGRAM § use Ame module import time! § recall that ! imporAng means to def c_to_f(c):! bring in that class return c*9/5 + 32 ! into your own file ! § start clock t0 = time.clock()! c_to_f(100000)! § call funcAon t1 = time.clock() - t0! § stop clock Print("t =", t, ":", t1, "s,”) ! 6 TIMING PROGRAMS IS INCONSISTENT § GOAL: to evaluate different algorithms § running Ame varies between algorithms § running Ame varies between implementa!ons § running Ame varies between computers § running Ame is not predictable based on small inputs § Ame varies for different inputs but cannot really express a relaAonship between inputs and Ame 7 COUNTING OPERATIONS § assume these steps take def c_to_f(c):! return c*9.0/5 + 32 ! constant !me: !
mathemaAcal operaAons def mysum(x):!
comparisons total = 0!
assignments for i in range(x+1):! total += i!
accessing objects in memory return total!
then count the number of operaAons executed as mysum à 1+3x ops funcAon of size of input 8 COUNTING OPERATIONS IS BETTER, BUT STILL… § GOAL: to evaluate different algorithms § count depends on algorithm § count depends on implementa!ons § count independent of computers § no clear definiAon of which opera!ons to count § count varies for different inputs and can come up with a relaAonship between inputs and the count 9 STILL NEED A BETTER WAY
Aming and counAng evaluate implementa!ons
Aming evaluates machines
want to evaluate algorithm
want to evaluate scalability
want to evaluate in terms of input size 10 STILL NEED A BETTER WAY § Going to focus on idea of counAng operaAons in an algorithm, but not worry about small variaAons in implementaAon (e.g., whether we take 3 or 4 primiAve operaAons to execute the steps of a loop) § Going to focus on how algorithm performs when size of problem gets arbitrarily large § Want to relate Ame needed to complete a computaAon, measured this way, against the size of the input to the problem § Need to decide what to measure, given that actual number of steps may depend on specifics of trial 11 NEED TO CHOOSE WHICH INPUT TO USE TO EVALUATE A FUNCTION § want to express efficiency in terms of size of input, so need to decide what your input is § could be an integer -- mysum(x) § could be length of list -- list_sum(L) § you decide when mulAple parameters to a funcAon -- search_for_elmt(L, e) 12 DIFFERENT INPUTS CHANGE HOW THE PROGRAM RUNS § a funcAon that searches for an element in a list def search_for_elmt(L, e):! for i in L:! if i == e:! return True! return False! § when e is first element in the list à BEST CASE § when e is not in list à WORST CASE § when look through about half of the elements in list à AVERAGE CASE § want to measure this behavior in a general way 13 BEST, AVERAGE, WORST CASES § suppose you are given a list L of some length len(L) § best case: minimum running Ame over all possible inputs of a given size, len(L)
constant for search_for_elmt
first element in any list § average case: average running Ame over all possible inputs of a given size, len(L)
pracAcal measure § worst case: maximum running Ame over all possible inputs of a given size, len(L)
linear in length of list for search_for_elmt
must search enAre list and not find it 14 ORDERS OF GROWTH Goals: § want to evaluate program’s efficiency when input is very big § want to express the growth of program’s run !me as input size grows § want to put an upper bound on growth – as Aght as possible § do not need to be precise: “order of” not “exact” growth § we will look at largest factors in run Ame (which secAon of the program will take the longest to run?) § thus, generally we want !ght upper bound on growth, as func!on of size of input, in worst case 15 MEASURING ORDER OF GROWTH: BIG OH NOTATION § Big Oh notaAon measures an upper bound on the asympto!c growth, oien called order of growth § Big Oh or O() is used to describe worst case
worst case occurs oien and is the boLleneck when a program runs
express rate of growth of program relaAve to the input size
evaluate algorithm NOT machine or implementaAon 16 EXACT STEPS vs O() def fact_iter(n):! """assumes n an int >= 0"""! answer = 1! while n > 1:! answer *= n! n -= 1! return answer! § computes factorial § number of steps: § worst case asymptoAc complexity:
ignore addiAve constants
ignore mulAplicaAve constants 17 WHAT DOES O(N) MEASURE? § Interested in describing how amount of Ame needed grows as size of (input to) problem grows § Thus, given an expression for the number of operaAons needed to compute an algorithm, want to know asymptoAc behavior as size of problem gets large § Hence, will focus on term that grows most rapidly in a sum of terms § And will ignore mulAplicaAve constants, since want to know how rapidly Ame required increases as increase size of input 18 SIMPLIFICATION EXAMPLES § drop constants and mulAplicaAve factors § focus on dominant terms : n2 + 2n + 2 O(n2 ) O(n2 ) : n2 + 100000n + 31000 O(n) : log(n) + n + 4 O(n log n) : 0.0001*n*log(n) + 300n O(3n ) : 2n30 + 3n 19 TYPES OF ORDERS OF GROWTH 20 ANALYZING PROGRAMS AND THEIR COMPLEXITY § combine complexity classes
analyze statements inside funcAons
apply some rules, focus on dominant term Law of Addi!on for O():
used with sequen!al statements
O(f(n)) + O(g(n)) is O( f(n) + g(n) )
for example, for i in range(n):! print('a')! for j in range(n*n):! print('b')! is O(n) + O(n*n) = O(n+n2) = O(n2) because of dominant term 21 ANALYZING PROGRAMS AND THEIR COMPLEXITY § combine complexity classes
analyze statements inside funcAons
apply some rules, focus on dominant term Law of Mul!plica!on for O():
used with nested statements/loops
O(f(n)) * O(g(n)) is O( f(n) * g(n) )
for example, for i in range(n):! for j in range(n):! print('a')! is O(n)*O(n) = O(n*n) = O(n2) because the outer loop goes n Ames and the inner loop goes n Ames for every outer loop iter. 22 COMPLEXITY CLASSES § O(1) denotes constant running Ame § O(log n) denotes logarithmic running Ame § O(n) denotes linear running Ame § O(n log n) denotes log-linear running Ame § O(nc) denotes polynomial running Ame (c is a constant) § O(cn) denotes exponenAal running Ame (c is a constant being raised to a power based on size of input) 23 COMPLEXITY CLASSES ORDERED LOW TO HIGH O(1) : constant O(log n) : logarithmic O(n) : linear O(n log n): loglinear O(nc) : polynomial O(cn) : exponenAal 24 COMPLEXITY GROWTH CLASS n=10 = 100 = 1000 = 1000000 O(1) 1 1 1 1 O(log n) 1 2 3 6 O(n) 10 100 1000 1000000 O(n log n) 10 200 3000 6000000 O(n^2) 100 10000 1000000 1000000000000 O(2^n) 1024 12676506 1071508607186267320948425049060 Good luck!! 00228229 0018105614048117055336074437503 40149670 8837035105112493612249319837881 3205376 5695858127594672917553146825187 1452856923140435984577574698574 8039345677748242309854210746050 6237114187795418215304647498358 1941267398767559165543946077062 9145711964776865421676604298316 52624386837205668069376 25 LINEAR COMPLEXITY § Simple iteraAve loop algorithms are typically linear in complexity 26 LINEAR SEARCH ON UNSORTED LIST def linear_search(L, e):! found = False! for i in range(len(L)):! if e == L[i]:! found = True! return found! § must look through all elements to decide it’s not there § O(len(L)) for the loop * O(1) to test if e == L[i]
O(1 + 4n + 1) = O(4n + 2) = O(n) § overall complexity is O(n) – where n is len(L) 27 CONSTANT TIME LIST ACCESS § if list is all ints …
ith element at
base + 4*i § if list is heterogeneous
indirecAon
references to other objects … 28 LINEAR SEARCH ON SORTED LIST def search(L, e):! for i in range(len(L)):! if L[i] == e:! return True! if L[i] > e:! return False! return False § must only look unAl reach a number greater than e § O(len(L)) for the loop * O(1) to test if e == L[i] § overall complexity is O(n) – where n is len(L) § NOTE: order of growth is same, though run Ame may differ for two search methods 29 LINEAR COMPLEXITY § searching a list in sequence to see if an element is present § add characters of a string, assumed to be composed of decimal digits def addDigits(s):! val = 0! for c in s:! val += int(c)! return val! § O(len(s)) 30 LINEAR COMPLEXITY § complexity oien depends on number of iteraAons def fact_iter(n):! prod = 1! for i in range(1, n+1):! prod *= i! return prod! § number of Ames around loop is n § number of operaAons inside loop is a constant (in this case, 3 – set i, mulAply, set prod)
O(1 + 3n + 1) = O(3n + 2) = O(n) § overall just O(n) 31 NESTED LOOPS § simple loops are linear in complexity § what about loops that have loops within them? 32 QUADRATIC COMPLEXITY determine if one list is subset of second, i.e., every element of first, appears in second (assume no duplicates) ! def isSubset(L1, L2):! for e1 in L1:! matched = False! for e2 in L2:! if e1 == e2:! matched = True! break! if not matched:! return False! return True! 33 QUADRATIC COMPLEXITY def isSubset(L1, L2):! outer loop executed len(L1) for e1 in L1:! Ames matched = False! each iteraAon will execute for e2 in L2:! inner loop up to len(L2) if e1 == e2:! Ames, with constant number matched = True! of operaAons break! if not matched:! O(len(L1)*len(L2)) return False! worst case when L1 and L2 return True! same length, none of elements of L1 in L2 O(len(L1)2) 34 QUADRATIC COMPLEXITY find intersecAon of two lists, return a list with each element appearing only once ! def intersect(L1, L2):! tmp = []! for e1 in L1:! for e2 in L2:! if e1 == e2:! tmp.append(e1)! res = []! for e in tmp:! if not(e in res):! res.append(e)! return res! 35 QUADRATIC COMPLEXITY def intersect(L1, L2):! first nested loop takes tmp = []! len(L1)*len(L2) steps for e1 in L1:! second loop takes at for e2 in L2:! most len(L1) steps if e1 == e2:! tmp.append(e1)! determining if element res = []! in list might take len(L1) for e in tmp:! steps if not(e in res):! res.append(e)! if we assume lists are of return res! roughly same length, then O(len(L1)^2) 36 O() FOR NESTED LOOPS def g(n):! """ assume n >= 0 """! x = 0! for i in range(n):! for j in range(n):! x += 1! return x! § computes n2 very inefficiently § when dealing with nested loops, look at the ranges § nested loops, each itera!ng n !mes § O(n2) 37 THIS TIME AND NEXT TIME § have seen examples of loops, and nested loops § give rise to linear and quadraAc complexity algorithms § next Ame, will more carefully examine examples from each of the different complexity classes 38 MIT OpenCourseWare https://ocw.mit.edu 6.0001 Introduction to Computer Science and Programming in Python Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.